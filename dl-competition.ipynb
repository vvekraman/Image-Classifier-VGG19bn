{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.models as models\n","import time\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import csv\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# check GPU availability\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Transformations applied on the image data\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5)]), p=0.5),\n","                                transforms.RandomHorizontalFlip()\n","                               ])                      \n","\n","transform_pred = transforms.Compose([transforms.ToTensor(), transforms.Resize((224,224))])\n","\n","# Loading the data set's\n","data_set = torchvision.datasets.ImageFolder(root='../input/dldatasetresized/train_resized', transform=transform)\n","pred_data = torchvision.datasets.ImageFolder(root='../input/dl-pred-data', transform=transform_pred)\n","\n","# Splitting the data for testing and training using random split under torch\n","train_set, test_set =torch.utils.data.random_split(data_set, (2980, 746)) # Train:Test/80:20\n","\n","# Image Data Loaders for training, testing and prediction\n","trainloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2) \n","testloader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)\n","predloader = torch.utils.data.DataLoader(pred_data, batch_size=1, shuffle=False, num_workers=2)\n","\n","classes = ('christmas_cookies', 'christmas_presents', 'christmas_tree', 'fireworks', 'penguin', 'reindeer', 'santa', 'snowman')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# functions to show an image\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print(' '.join('%5s' % classes[labels[j]] for j in range(64)))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["vgg16 = models.vgg19_bn(pretrained=True)\n","\n","\n","# change the number of classes \n","vgg16.classifier[6].out_features = 8\n","\n","# freeze convolution weights\n","for param in vgg16.features.parameters():\n","    param.requires_grad = False\n","\"\"\"\"\"\n","vgg16.classifier[0].out_features = 10096\n","vgg16.classifier[3].in_features = 10096\n","vgg16.classifier[3].out_features = 4096\n","vgg16.classifier[6].in_features = 4096\n","vgg16.classifier[6].out_features = 8\n","\n","\n","vgg16.classifier.add_module(\"7\", torch.nn.ReLU(inplace=True))\n","vgg16.classifier.add_module(\"8\", torch.nn.Dropout(p=0.5, inplace=False))\n","vgg16.classifier.add_module(\"9\", torch.nn.Linear(in_features=4096, out_features=1096, bias=True))\n","vgg16.classifier.add_module(\"10\", torch.nn.ReLU(inplace=True))\n","vgg16.classifier.add_module(\"11\", torch.nn.Dropout(p=0.5, inplace=False))\n","vgg16.classifier.add_module(\"12\", torch.nn.Linear(in_features=1096, out_features=8, bias=True))  \n","\"\"\"\n","vgg16.to(device)\n","print(vgg16)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["vgg16 = models.densenet201(pretrained=True)\n","#vgg16 = models.vgg19_bn(pretrained=True)\n","vgg16.to(device)\n","\n","# change the number of classes \n","vgg16.classifier.out_features = 8\n","\n","# freeze convolution weights\n","for param in vgg16.features.parameters():\n","    param.requires_grad = False\n","    \n","#print(vgg16)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# optimizer\n","optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.01, momentum=0.9)\n","#optimizer = torch.optim.Adam(vgg16.classifier.parameters(), lr=0.001, amsgrad=False)\n","\n","# loss function\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# optimizer\n","#optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.005, momentum=0.9)\n","#optimizer = torch.optim.Adam(vgg16.classifier.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n","\n","# loss function\n","#criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# training function\n","def fit(model, train_dataloader, epoch, n_epochs):\n","\n","    model.train()\n","\n","    train_running_loss = 0.0\n","    train_running_correct = 0\n","\n","    print(f'Epoch {epoch+1}/{n_epochs}')\n","    #pbar = tf.keras.utils.Progbar(target=len(train_dataloader))\n","\n","    for i, data in enumerate(train_dataloader):\n","        data, target = data[0].to(device), data[1].to(device)\n","        optimizer.zero_grad()  # set the gradients to zero before starting to do backpropragation\n","        output = model(data)\n","        loss = criterion(output, target)\n","        train_running_loss += loss.item()\n","        _, preds = torch.max(output.data, 1) # takes the highest val in an array and removes the rest, also returns the index of the highest value\n","        train_running_correct += (preds == target).sum().item()\n","        loss.backward() # computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x\n","        optimizer.step() # updates the value of x using the gradient x.grad\n","        #pbar.update(i, values=[(\"loss\",train_running_loss/len(train_dataloader.dataset))])\n","\n","    train_loss = train_running_loss/len(train_dataloader.dataset)\n","    train_accuracy = 100. * train_running_correct/len(train_dataloader.dataset)\n","    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}')\n","    \n","    return train_loss, train_accuracy"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# validation/test function\n","def validate(model, test_dataloader):\n","    \n","    model.eval() # Dropout layer inactive\n","    \n","    val_running_loss = 0.0\n","    val_running_correct = 0\n","    \n","    for i, data in enumerate(test_dataloader):\n","        data, target = data[0].to(device), data[1].to(device)\n","        output = model(data)\n","        loss = criterion(output, target)  \n","        val_running_loss += loss.item()\n","        _, preds = torch.max(output.data, 1)\n","        val_running_correct += (preds == target).sum().item()\n","    \n","    val_loss = val_running_loss/len(test_dataloader.dataset)\n","    val_accuracy = 100. * val_running_correct/len(test_dataloader.dataset)\n","    print('Validation Loss: ',val_loss , '  Validation Acc: ', val_accuracy)\n","    \n","    return val_loss, val_accuracy"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# epoch\n","train_loss , train_accuracy = [], []\n","val_loss , val_accuracy = [], []\n","\n","start = time.time()\n","n_epochs = 25\n","\n","for epoch in range(n_epochs):\n","    train_epoch_loss, train_epoch_accuracy = fit(vgg16, trainloader, epoch, n_epochs)\n","    val_epoch_loss, val_epoch_accuracy = validate(vgg16, testloader)\n","    \n","    # save the whole model\n","    torch.save(vgg16, 'entire_model_ep' + str(epoch+1) + '.pt')\n","    \n","    train_loss.append(train_epoch_loss)\n","    #train_accuracy.append(train_epoch_accuracy)\n","    \n","    val_loss.append(val_epoch_loss)\n","    #val_accuracy.append(val_epoch_accuracy)\n","\n","end = time.time()\n","\n","print((end-start)/60, 'minutes')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# train/val accuracy plot\n","plt.figure(figsize=(10, 7))\n","\n","plt.plot(train_accuracy, color='green', label='train accuracy')\n","plt.plot(val_accuracy, color='blue', label='validataion accuracy')\n","plt.legend()\n","\n","plt.savefig('accuracy.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# train/val loss plot\n","plt.figure(figsize=(10, 7))\n","\n","plt.plot(train_loss, color='orange', label='train loss')\n","plt.plot(val_loss, color='red', label='validataion loss')\n","plt.legend()\n","\n","plt.savefig('loss.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["# load model\n","model = torch.load('entire_model_ep9.pt')\n","model.to(device)\n","#print(model)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# save the state_dict()\n","PATH = 'entire_model_ep2_statedict().pth'\n","torch.save(model.state_dict(), PATH)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["model = models.vgg16_bn(pretrained=True)\n","model.load_state_dict(torch.load(PATH))\n","\n","print(\"Model's state_dict:\")\n","for param_tensor in model.state_dict():\n","    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# prediction fn\n","def prediction(model, predloader):\n","    \n","    model.eval()\n","    \n","    result = {}\n","    \n","    for count, data in enumerate(predloader):\n","        data = data[0].to(device)\n","        output = model(data)\n","        _,preds = torch.max(output.data, 1)\n","        sample_fname, _ = predloader.dataset.samples[count]\n","        result[sample_fname[26:-4]] = preds[0].item() \n","    return result\n","        "],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# prediction\n","a = prediction(model, predloader)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(a)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["with open('predictions.csv', 'w') as f:\n","    writer = csv.DictWriter(f, fieldnames=[\"Id\", \"Category\"])\n","    writer.writeheader()\n","    [f.write('{0},{1}\\n'.format(key, value)) for key, value in a.items()]"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.5-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}